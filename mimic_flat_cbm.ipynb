{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT3fh7wau5mEFFORg9iE6M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikitaN65/HelloWorld/blob/main/mimic_flat_cbm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CLFW-ygOUnHZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P39WyzSDwb-g",
        "outputId": "6a281a92-5423-4a53-bfac-251f8c98df2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mpl.rcParams.update(mpl.rcParamsDefault)\n",
        "plt.rcParams['font.size'] = 20"
      ],
      "metadata": {
        "id": "SMON5ffTlgeE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset\n",
        "\n",
        "# class PatientDataset(Dataset):\n",
        "#     def __init__(self, patient_info, drg_codes, filepath_features):\n",
        "#         patient_df = pd.read_csv(patient_info)\n",
        "#         codes_df = pd.read_csv(drg_codes)\n",
        "#         features_df = pd.read_csv(filepath_features)\n",
        "\n",
        "#         # Pivot the features dataframe\n",
        "#         features_pivot = features_df.pivot_table(index='subject_id', columns='itemid', values='average_value', aggfunc=np.mean)\n",
        "#         features_pivot.reset_index(inplace=True)\n",
        "\n",
        "#         # Merge datasets - first the codes and patient info, then the features. N/A if a particular feature doesn't have a match\n",
        "#         df = pd.merge(pd.merge(patient_df, codes_df, on=['subject_id', 'hadm_id']), features_pivot, on='subject_id', how='left')\n",
        "\n",
        "#         # Convert gender to numeric\n",
        "#         df['gender'] = df['gender'].map({'M': 0, 'F': 1})\n",
        "\n",
        "#         columns_to_remove = ['intime', 'outtime', 'los', 'admission_type', 'deathtime', 'anchor_age', 'anchor_year', 'anchor_year_group', 'hadm_id', 'description']  # remove columns I don't need for now\n",
        "#         df = df.drop(columns=columns_to_remove, axis=1)\n",
        "#         df = df.drop_duplicates()\n",
        "\n",
        "\n",
        "\n",
        "#         print(df.head(100))\n",
        "\n",
        "\n",
        "#         # Remove non-feature columns before creating indicators\n",
        "#         feature_columns = df.columns.difference(['subject_id', 'hadm_id', 'drg_code'])\n",
        "#         df_features_only = df[feature_columns]\n",
        "\n",
        "#         # Initialize a matrix for indicators (1 if present, 0 if missing) based on feature columns only\n",
        "#         indicators = df_features_only.isna().astype(int).values\n",
        "\n",
        "\n",
        "#         self.features = df_features_only.values\n",
        "#         self.indicators = indicators\n",
        "#         self.targets = df['drg_code'].values\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.targets)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         features_with_indicators = np.concatenate([self.features[idx], self.indicators[idx]], axis=0)\n",
        "#         features_with_indicators = features_with_indicators.astype(np.float32)\n",
        "#         features_tensor = torch.tensor(features_with_indicators, dtype=torch.float32)\n",
        "#         features_tensor[torch.isnan(features_tensor)] = 2500  # Placeholder value for NaNs\n",
        "#         target = torch.tensor(self.targets[idx], dtype=torch.long)\n",
        "#         return features_tensor, target\n",
        "\n"
      ],
      "metadata": {
        "id": "PwM-9yMMh3Vi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "class PatientDataset(Dataset):\n",
        "    def __init__(self, patient_info, drg_codes, filepath_features):\n",
        "        patient_df = pd.read_csv(patient_info)\n",
        "        codes_df = pd.read_csv(drg_codes)\n",
        "        codes_df.drop(columns = 'description', inplace=True)\n",
        "        codes_df = codes_df.drop_duplicates()\n",
        "        features_df = pd.read_csv(filepath_features)\n",
        "\n",
        "        # Group by subject_id (and hadm_id if necessary) and aggregate DRG codes into lists\n",
        "        aggregated_drg = codes_df.groupby(['subject_id', 'hadm_id'])['drg_code'].apply(list).reset_index()\n",
        "\n",
        "        # Check uniqueness in patient_df\n",
        "        print(patient_df[['subject_id', 'hadm_id']].duplicated().any())\n",
        "\n",
        "\n",
        "        # Assuming 'itemid' and 'average_value' are columns in your features_df\n",
        "        features_pivot = features_df.pivot_table(index='subject_id', columns='itemid', values='average_value', aggfunc=np.mean)\n",
        "        features_pivot.reset_index(inplace=True)\n",
        "\n",
        "        print(features_pivot)\n",
        "        print('patient_df', patient_df)\n",
        "        print('aggregated_drg', aggregated_drg)\n",
        "\n",
        "        # Merge patient info with DRG codes, then with features\n",
        "        initial_df = pd.merge(patient_df, aggregated_drg, on=['subject_id', 'hadm_id'])\n",
        "        print('initial df, after merging patient and codes', initial_df)\n",
        "        # Check uniqueness in codes_df\n",
        "        print(initial_df[['subject_id', 'hadm_id']].duplicated().any())\n",
        "        df = pd.merge(initial_df, features_pivot, on='subject_id', how='left')\n",
        "        print('merged df before removing unnecessary columns', df)\n",
        "\n",
        "        # removing unnecessary columns and removing duplicates (from when I grouped together similar conditions)\n",
        "        columns_to_remove = ['intime', 'outtime', 'los', 'admission_type', 'deathtime', 'anchor_age', 'anchor_year', 'anchor_year_group', 'hadm_id']\n",
        "        df.drop(columns=columns_to_remove, inplace=True, errors='ignore')\n",
        "\n",
        "\n",
        "        # Convert gender to numeric\n",
        "        df['gender'] = df['gender'].map({'M': 0, 'F': 1}).astype(int)\n",
        "\n",
        "        print(df)\n",
        "\n",
        "        # # Group by subject_id and aggregate DRG codes into lists\n",
        "        # df_grouped = df.groupby('subject_id').agg({'drg_code': lambda x: list(x)}).reset_index()\n",
        "\n",
        "        # print(df_grouped.head(100))\n",
        "\n",
        "        # Initialize MultiLabelBinarizer for DRG codes\n",
        "        mlb = MultiLabelBinarizer()\n",
        "        self.targets = mlb.fit_transform(aggregated_drg['drg_code'])\n",
        "\n",
        "        # # Merge grouped DRG codes with features (ensuring one row per patient)\n",
        "        # df_final = pd.merge(df_grouped[['subject_id']], features_pivot, on='subject_id', how='right')\n",
        "\n",
        "        # Prepare features and indicators\n",
        "        feature_columns = df.columns.difference(['subject_id', 'drg_code'])\n",
        "        self.features = df[feature_columns].values\n",
        "        indicators = np.isnan(self.features).astype(int)\n",
        "        self.features[np.isnan(self.features)] = 2500  # Replace NaN with 0 or another placeholder\n",
        "\n",
        "        # Concatenate features and indicators\n",
        "        self.features_with_indicators = np.concatenate([self.features, indicators], axis=1).astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features_tensor = torch.tensor(self.features_with_indicators[idx], dtype=torch.float32)\n",
        "        target_tensor = torch.tensor(self.targets[idx], dtype=torch.float32)  # Use float for probability targets\n",
        "        return features_tensor, target_tensor\n"
      ],
      "metadata": {
        "id": "5gEeZk-8GN15"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# class PatientDataset(Dataset):\n",
        "#     def __init__(self, filepath_info, filepath_codes):\n",
        "#         # Load and preprocess data\n",
        "#         info_df = pd.read_csv(filepath_info)\n",
        "#         codes_df = pd.read_csv(filepath_codes)\n",
        "\n",
        "#         # Join datasets on 'subject_id'\n",
        "#         df = pd.merge(info_df, codes_df, on=['subject_id', 'hadm_id'])\n",
        "\n",
        "#         # Convert gender to numeric (e.g., M=0, F=1)\n",
        "#         df['gender'] = df['gender'].map({'M': 0, 'F': 1})\n",
        "\n",
        "#         self.features = df[['age_at_admission', 'gender']].values\n",
        "#         self.targets = df['drg_code'].values\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.targets)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         features = torch.tensor(self.features[idx], dtype=torch.float)\n",
        "#         target = torch.tensor(self.targets[idx], dtype=torch.long)\n",
        "#         return features, target"
      ],
      "metadata": {
        "id": "yP-n0fsXU0so"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = PatientDataset('/content/drive/My Drive/Colab Notebooks/CBMS_animal_dataset/patients_with_chosen_conditions.csv', '/content/drive/My Drive/Colab Notebooks/CBMS_animal_dataset/patient_drg_codes_specific_conditions_only.csv', '/content/drive/My Drive/Colab Notebooks/CBMS_animal_dataset/average_values.csv')\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "for features, target in dataloader:\n",
        "    print(features, target)\n",
        "    print(features.shape)\n",
        "    print(target.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noBzX1xCU_xy",
        "outputId": "dc32a08e-36ea-458a-9a32-6115b4b02cf8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "itemid  subject_id      220045      220050     220051     220052     220059  \\\n",
            "0         10002013   94.214286  110.619048  61.476190  76.700000  26.812500   \n",
            "1         10002430   79.185714         NaN        NaN        NaN        NaN   \n",
            "2         10002760   72.653846  108.434783  57.521739  74.217391  39.869565   \n",
            "3         10003046  106.924528  112.150943  70.490566  81.962264        NaN   \n",
            "4         10003502   59.960000         NaN        NaN        NaN        NaN   \n",
            "...            ...         ...         ...        ...        ...        ...   \n",
            "15079     19995258  108.760870         NaN        NaN        NaN        NaN   \n",
            "15080     19995790   85.366667  113.130435  59.521739  76.478261  36.800000   \n",
            "15081     19996783   83.896552         NaN        NaN        NaN        NaN   \n",
            "15082     19997448   90.083333  128.000000  64.781250  86.000000        NaN   \n",
            "15083     19997843   76.176471         NaN        NaN        NaN        NaN   \n",
            "\n",
            "itemid     220060     220061     220074  220088  ...  227686  228872  228873  \\\n",
            "0       16.437500  20.875000  12.000000   4.348  ...     NaN     NaN     NaN   \n",
            "1             NaN        NaN        NaN     NaN  ...     NaN     NaN     NaN   \n",
            "2       20.956522  27.521739  14.478261     NaN  ...     NaN     NaN     NaN   \n",
            "3             NaN        NaN        NaN     NaN  ...     NaN     NaN     NaN   \n",
            "4             NaN        NaN        NaN     NaN  ...     NaN     NaN     NaN   \n",
            "...           ...        ...        ...     ...  ...     ...     ...     ...   \n",
            "15079         NaN        NaN        NaN     NaN  ...     NaN     NaN     NaN   \n",
            "15080   18.050000  25.000000  25.400000   7.065  ...     NaN     NaN     NaN   \n",
            "15081         NaN        NaN        NaN     NaN  ...     NaN     NaN     NaN   \n",
            "15082         NaN        NaN        NaN     NaN  ...     NaN     NaN     NaN   \n",
            "15083         NaN        NaN        NaN     NaN  ...     NaN     NaN     NaN   \n",
            "\n",
            "itemid  228874  228875  228876  229235  229236  229317  229761  \n",
            "0          NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "1          NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "2          NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "3          NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "4          NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "...        ...     ...     ...     ...     ...     ...     ...  \n",
            "15079      NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "15080      NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "15081      NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "15082      NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "15083      NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "\n",
            "[15084 rows x 108 columns]\n",
            "patient_df        subject_id   hadm_id   stay_id               intime  \\\n",
            "0        10002013  23581541  39060235  2160-05-18 10:00:53   \n",
            "1        10002430  26295318  38392119  2129-06-13 00:43:08   \n",
            "2        10002760  28094813  31831386  2141-04-20 13:20:46   \n",
            "3        10003046  26048429  35514836  2154-01-02 15:57:15   \n",
            "4        10003502  29011269  35796366  2169-08-26 21:30:32   \n",
            "...           ...       ...       ...                  ...   \n",
            "15079    19995258  26871572  38607853  2130-06-10 19:49:07   \n",
            "15080    19995790  22970553  34995866  2185-02-02 11:29:40   \n",
            "15081    19996783  21880161  35175329  2188-05-11 11:59:31   \n",
            "15082    19997448  23560173  38134381  2122-07-27 02:53:13   \n",
            "15083    19997843  20277361  32880062  2120-11-18 02:39:00   \n",
            "\n",
            "                   outtime       los               admission_type deathtime  \\\n",
            "0      2160-05-19 17:33:33  1.314352  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "1      2129-06-15 22:51:40  2.922593                       URGENT       NaN   \n",
            "2      2141-04-21 14:26:49  1.045868  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "3      2154-01-04 15:19:56  1.974086  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "4      2169-08-27 22:27:21  1.039456            OBSERVATION ADMIT       NaN   \n",
            "...                    ...       ...                          ...       ...   \n",
            "15079  2130-06-12 17:23:10  1.898646                       URGENT       NaN   \n",
            "15080  2185-02-03 16:03:15  1.189988  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "15081  2188-05-13 21:13:47  2.384907            OBSERVATION ADMIT       NaN   \n",
            "15082  2122-07-28 12:33:32  1.402998                     ELECTIVE       NaN   \n",
            "15083  2120-11-20 23:02:24  2.849583                     EW EMER.       NaN   \n",
            "\n",
            "       anchor_age  anchor_year anchor_year_group  age_at_admission gender  \n",
            "0              53         2156       2008 - 2010                57      F  \n",
            "1              86         2125       2014 - 2016                90      M  \n",
            "2              56         2141       2008 - 2010                56      M  \n",
            "3              64         2154       2011 - 2013                64      M  \n",
            "4              86         2161       2008 - 2010                94      F  \n",
            "...           ...          ...               ...               ...    ...  \n",
            "15079          57         2125       2011 - 2013                62      F  \n",
            "15080          66         2185       2008 - 2010                66      M  \n",
            "15081          89         2188       2017 - 2019                89      M  \n",
            "15082          52         2121       2014 - 2016                53      F  \n",
            "15083          47         2120       2017 - 2019                47      M  \n",
            "\n",
            "[15084 rows x 13 columns]\n",
            "aggregated_drg        subject_id   hadm_id drg_code\n",
            "0        10002013  23581541    [166]\n",
            "1        10002430  26295318    [194]\n",
            "2        10002760  28094813    [163]\n",
            "3        10003046  26048429    [163]\n",
            "4        10003502  29011269    [201]\n",
            "...           ...       ...      ...\n",
            "15079    19995258  26871572    [329]\n",
            "15080    19995790  22970553    [166]\n",
            "15081    19996783  21880161    [190]\n",
            "15082    19997448  23560173    [163]\n",
            "15083    19997843  20277361    [775]\n",
            "\n",
            "[15084 rows x 3 columns]\n",
            "initial df, after merging patient and codes        subject_id   hadm_id   stay_id               intime  \\\n",
            "0        10002013  23581541  39060235  2160-05-18 10:00:53   \n",
            "1        10002430  26295318  38392119  2129-06-13 00:43:08   \n",
            "2        10002760  28094813  31831386  2141-04-20 13:20:46   \n",
            "3        10003046  26048429  35514836  2154-01-02 15:57:15   \n",
            "4        10003502  29011269  35796366  2169-08-26 21:30:32   \n",
            "...           ...       ...       ...                  ...   \n",
            "15079    19995258  26871572  38607853  2130-06-10 19:49:07   \n",
            "15080    19995790  22970553  34995866  2185-02-02 11:29:40   \n",
            "15081    19996783  21880161  35175329  2188-05-11 11:59:31   \n",
            "15082    19997448  23560173  38134381  2122-07-27 02:53:13   \n",
            "15083    19997843  20277361  32880062  2120-11-18 02:39:00   \n",
            "\n",
            "                   outtime       los               admission_type deathtime  \\\n",
            "0      2160-05-19 17:33:33  1.314352  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "1      2129-06-15 22:51:40  2.922593                       URGENT       NaN   \n",
            "2      2141-04-21 14:26:49  1.045868  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "3      2154-01-04 15:19:56  1.974086  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "4      2169-08-27 22:27:21  1.039456            OBSERVATION ADMIT       NaN   \n",
            "...                    ...       ...                          ...       ...   \n",
            "15079  2130-06-12 17:23:10  1.898646                       URGENT       NaN   \n",
            "15080  2185-02-03 16:03:15  1.189988  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "15081  2188-05-13 21:13:47  2.384907            OBSERVATION ADMIT       NaN   \n",
            "15082  2122-07-28 12:33:32  1.402998                     ELECTIVE       NaN   \n",
            "15083  2120-11-20 23:02:24  2.849583                     EW EMER.       NaN   \n",
            "\n",
            "       anchor_age  anchor_year anchor_year_group  age_at_admission gender  \\\n",
            "0              53         2156       2008 - 2010                57      F   \n",
            "1              86         2125       2014 - 2016                90      M   \n",
            "2              56         2141       2008 - 2010                56      M   \n",
            "3              64         2154       2011 - 2013                64      M   \n",
            "4              86         2161       2008 - 2010                94      F   \n",
            "...           ...          ...               ...               ...    ...   \n",
            "15079          57         2125       2011 - 2013                62      F   \n",
            "15080          66         2185       2008 - 2010                66      M   \n",
            "15081          89         2188       2017 - 2019                89      M   \n",
            "15082          52         2121       2014 - 2016                53      F   \n",
            "15083          47         2120       2017 - 2019                47      M   \n",
            "\n",
            "      drg_code  \n",
            "0        [166]  \n",
            "1        [194]  \n",
            "2        [163]  \n",
            "3        [163]  \n",
            "4        [201]  \n",
            "...        ...  \n",
            "15079    [329]  \n",
            "15080    [166]  \n",
            "15081    [190]  \n",
            "15082    [163]  \n",
            "15083    [775]  \n",
            "\n",
            "[15084 rows x 14 columns]\n",
            "False\n",
            "merged df before removing unnecessary columns        subject_id   hadm_id   stay_id               intime  \\\n",
            "0        10002013  23581541  39060235  2160-05-18 10:00:53   \n",
            "1        10002430  26295318  38392119  2129-06-13 00:43:08   \n",
            "2        10002760  28094813  31831386  2141-04-20 13:20:46   \n",
            "3        10003046  26048429  35514836  2154-01-02 15:57:15   \n",
            "4        10003502  29011269  35796366  2169-08-26 21:30:32   \n",
            "...           ...       ...       ...                  ...   \n",
            "15079    19995258  26871572  38607853  2130-06-10 19:49:07   \n",
            "15080    19995790  22970553  34995866  2185-02-02 11:29:40   \n",
            "15081    19996783  21880161  35175329  2188-05-11 11:59:31   \n",
            "15082    19997448  23560173  38134381  2122-07-27 02:53:13   \n",
            "15083    19997843  20277361  32880062  2120-11-18 02:39:00   \n",
            "\n",
            "                   outtime       los               admission_type deathtime  \\\n",
            "0      2160-05-19 17:33:33  1.314352  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "1      2129-06-15 22:51:40  2.922593                       URGENT       NaN   \n",
            "2      2141-04-21 14:26:49  1.045868  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "3      2154-01-04 15:19:56  1.974086  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "4      2169-08-27 22:27:21  1.039456            OBSERVATION ADMIT       NaN   \n",
            "...                    ...       ...                          ...       ...   \n",
            "15079  2130-06-12 17:23:10  1.898646                       URGENT       NaN   \n",
            "15080  2185-02-03 16:03:15  1.189988  SURGICAL SAME DAY ADMISSION       NaN   \n",
            "15081  2188-05-13 21:13:47  2.384907            OBSERVATION ADMIT       NaN   \n",
            "15082  2122-07-28 12:33:32  1.402998                     ELECTIVE       NaN   \n",
            "15083  2120-11-20 23:02:24  2.849583                     EW EMER.       NaN   \n",
            "\n",
            "       anchor_age  anchor_year  ... 227686  228872 228873 228874  228875  \\\n",
            "0              53         2156  ...    NaN     NaN    NaN    NaN     NaN   \n",
            "1              86         2125  ...    NaN     NaN    NaN    NaN     NaN   \n",
            "2              56         2141  ...    NaN     NaN    NaN    NaN     NaN   \n",
            "3              64         2154  ...    NaN     NaN    NaN    NaN     NaN   \n",
            "4              86         2161  ...    NaN     NaN    NaN    NaN     NaN   \n",
            "...           ...          ...  ...    ...     ...    ...    ...     ...   \n",
            "15079          57         2125  ...    NaN     NaN    NaN    NaN     NaN   \n",
            "15080          66         2185  ...    NaN     NaN    NaN    NaN     NaN   \n",
            "15081          89         2188  ...    NaN     NaN    NaN    NaN     NaN   \n",
            "15082          52         2121  ...    NaN     NaN    NaN    NaN     NaN   \n",
            "15083          47         2120  ...    NaN     NaN    NaN    NaN     NaN   \n",
            "\n",
            "       228876  229235  229236  229317  229761  \n",
            "0         NaN     NaN     NaN     NaN     NaN  \n",
            "1         NaN     NaN     NaN     NaN     NaN  \n",
            "2         NaN     NaN     NaN     NaN     NaN  \n",
            "3         NaN     NaN     NaN     NaN     NaN  \n",
            "4         NaN     NaN     NaN     NaN     NaN  \n",
            "...       ...     ...     ...     ...     ...  \n",
            "15079     NaN     NaN     NaN     NaN     NaN  \n",
            "15080     NaN     NaN     NaN     NaN     NaN  \n",
            "15081     NaN     NaN     NaN     NaN     NaN  \n",
            "15082     NaN     NaN     NaN     NaN     NaN  \n",
            "15083     NaN     NaN     NaN     NaN     NaN  \n",
            "\n",
            "[15084 rows x 121 columns]\n",
            "       subject_id   stay_id  age_at_admission  gender drg_code      220045  \\\n",
            "0        10002013  39060235                57       1    [166]   94.214286   \n",
            "1        10002430  38392119                90       0    [194]   79.185714   \n",
            "2        10002760  31831386                56       0    [163]   72.653846   \n",
            "3        10003046  35514836                64       0    [163]  106.924528   \n",
            "4        10003502  35796366                94       1    [201]   59.960000   \n",
            "...           ...       ...               ...     ...      ...         ...   \n",
            "15079    19995258  38607853                62       1    [329]  108.760870   \n",
            "15080    19995790  34995866                66       0    [166]   85.366667   \n",
            "15081    19996783  35175329                89       0    [190]   83.896552   \n",
            "15082    19997448  38134381                53       1    [163]   90.083333   \n",
            "15083    19997843  32880062                47       0    [775]   76.176471   \n",
            "\n",
            "           220050     220051     220052     220059  ...  227686  228872  \\\n",
            "0      110.619048  61.476190  76.700000  26.812500  ...     NaN     NaN   \n",
            "1             NaN        NaN        NaN        NaN  ...     NaN     NaN   \n",
            "2      108.434783  57.521739  74.217391  39.869565  ...     NaN     NaN   \n",
            "3      112.150943  70.490566  81.962264        NaN  ...     NaN     NaN   \n",
            "4             NaN        NaN        NaN        NaN  ...     NaN     NaN   \n",
            "...           ...        ...        ...        ...  ...     ...     ...   \n",
            "15079         NaN        NaN        NaN        NaN  ...     NaN     NaN   \n",
            "15080  113.130435  59.521739  76.478261  36.800000  ...     NaN     NaN   \n",
            "15081         NaN        NaN        NaN        NaN  ...     NaN     NaN   \n",
            "15082  128.000000  64.781250  86.000000        NaN  ...     NaN     NaN   \n",
            "15083         NaN        NaN        NaN        NaN  ...     NaN     NaN   \n",
            "\n",
            "       228873  228874  228875  228876  229235  229236  229317  229761  \n",
            "0         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "1         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "2         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "3         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "4         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "...       ...     ...     ...     ...     ...     ...     ...     ...  \n",
            "15079     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "15080     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "15081     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "15082     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "15083     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
            "\n",
            "[15084 rows x 112 columns]\n",
            "tensor([[  66.3000, 2500.0000, 2500.0000,  ...,    0.0000,    0.0000,\n",
            "            0.0000],\n",
            "        [  92.2895, 2500.0000, 2500.0000,  ...,    0.0000,    0.0000,\n",
            "            0.0000],\n",
            "        [  73.5375,   94.0323,   36.9355,  ...,    0.0000,    0.0000,\n",
            "            0.0000],\n",
            "        ...,\n",
            "        [  80.3056, 2500.0000, 2500.0000,  ...,    0.0000,    0.0000,\n",
            "            0.0000],\n",
            "        [  92.6250, 2500.0000, 2500.0000,  ...,    0.0000,    0.0000,\n",
            "            0.0000],\n",
            "        [  97.9444,  109.0000,   59.6429,  ...,    0.0000,    0.0000,\n",
            "            0.0000]]) tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "torch.Size([32, 220])\n",
            "torch.Size([32, 43])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim):\n",
        "        super(model, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        probabilities = F.softmax(x, dim=1)\n",
        "\n",
        "        return probabilities\n",
        "\n",
        "\n",
        "# try 30 latent dims for predicting concepts\n",
        "# between 14-50 for c to y\n"
      ],
      "metadata": {
        "id": "4tVvFRbgXEdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(x_sz,c_sz, y_sz, c_dim, y_dim, lr, lr_2, epochs):\n",
        "    # define the input and output sizes\n",
        "    torch.manual_seed(25)\n",
        "    x_to_c = model(x_sz, c_sz, c_dim)\n",
        "    c_to_y = model(c_sz, y_sz, y_dim)\n",
        "\n",
        "\n",
        "    # define the loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(x_to_c.parameters(), lr=lr)\n",
        "    yoptimizer = torch.optim.SGD(c_to_y.parameters(), lr=lr_2)\n",
        "\n",
        "\n",
        "    epochs_cnt = []\n",
        "    xclosses = []\n",
        "    cylosses = []\n",
        "    pred_c_list = []\n",
        "    correct_c = []\n",
        "    pred_y_list = []\n",
        "    correct_y = []\n",
        "\n",
        "    num_epochs = epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        running_xc_loss = 0.0\n",
        "        running_cy_loss = 0.0\n",
        "        epochs_cnt.append(epoch)\n",
        "\n",
        "        for i, batch in enumerate(data_loader):\n",
        "\n",
        "            x, y, c = batch\n",
        "\n",
        "            correct_c.append(c)\n",
        "            correct_y.append(y)\n",
        "\n",
        "            x = x.to(x_to_c.linear1.weight.dtype)\n",
        "\n",
        "            # forward pass\n",
        "\n",
        "            # model.train()\n",
        "\n",
        "\n",
        "            pred_c = x_to_c(x)\n",
        "            pred_c_list.append(pred_c.detach().numpy())\n",
        "            lossc = criterion(pred_c, c)\n",
        "\n",
        "\n",
        "            # backward pass\n",
        "            optimizer.zero_grad()\n",
        "            lossc.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pred_y = c_to_y(pred_c.detach())\n",
        "            pred_y_list.append(pred_y.detach().numpy())\n",
        "            lossy = criterion(pred_y, y)\n",
        "\n",
        "            # backward pass\n",
        "            yoptimizer.zero_grad()\n",
        "            lossy.backward()\n",
        "            yoptimizer.step()\n",
        "\n",
        "            running_xc_loss += lossc.item()\n",
        "            running_cy_loss += lossy.item()\n",
        "\n",
        "        xclosses.append(running_xc_loss/len(data_loader))\n",
        "        cylosses.append(running_cy_loss/len(data_loader))\n",
        "\n",
        "\n",
        "    return xclosses, cylosses, pred_c_list, pred_y_list, epochs_cnt, correct_c, correct_y"
      ],
      "metadata": {
        "id": "JD9S_NFgXJPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_and_save_accuracy(c_classes, epoch_cnt, l, l_2, pred_c_list, c, name):\n",
        "    # Number of classes\n",
        "    c_classes = c_classes\n",
        "\n",
        "    # Create tensors to store class accuracies, false positives, and false negatives\n",
        "    class_accuracies = torch.zeros(c_classes)\n",
        "    false_positives = torch.zeros(c_classes)\n",
        "    false_negatives = torch.zeros(c_classes)\n",
        "\n",
        "    # Create variables to store total correct and total comparisons for overall accuracy\n",
        "    total_correct = 0\n",
        "    total_comparisons = 0\n",
        "\n",
        "    # Define file path for saving results\n",
        "    file_path = f\"{name}_accuracy_flat_seq_{epoch_cnt}_{l}_{l_2}.txt\"\n",
        "\n",
        "    # Correct shapes\n",
        "    pred_c_tensor = torch.tensor(pred_c_list)\n",
        "    pred_c = pred_c_tensor.view(-1, pred_c_tensor.size(-1))\n",
        "    pred_c = (pred_c > 1 / c_classes).float()\n",
        "    c_flat = torch.cat(c, dim=0)\n",
        "\n",
        "    # Restrict the data to the last 500 samples\n",
        "    pred_c = pred_c[-500:]\n",
        "    c_flat = c_flat[-500:]\n",
        "\n",
        "    # Calculate class accuracies, false positives, false negatives, and overall accuracy\n",
        "    for class_idx in range(c_classes):\n",
        "        correct = torch.sum(((pred_c[:, class_idx] == 1) & (c_flat[:, class_idx] == 1)) | ((pred_c[:, class_idx] == 0) & (c_flat[:, class_idx] == 0)))\n",
        "        total = 500\n",
        "        false_positive = torch.sum((pred_c[:, class_idx] == 1) & (c_flat[:, class_idx] == 0))\n",
        "        false_negative = torch.sum((pred_c[:, class_idx] == 0) & (c_flat[:, class_idx] == 1))\n",
        "\n",
        "        # Calculate class accuracy as a percentage\n",
        "        class_accuracy = (correct.float() / total) * 100\n",
        "        class_accuracies[class_idx] = class_accuracy\n",
        "\n",
        "        # Calculate false positives and false negatives as percentages\n",
        "        false_positives[class_idx] = (false_positive.float() / torch.sum(c_flat[:, class_idx] == 0)) * 100\n",
        "        false_negatives[class_idx] = (false_negative.float() / torch.sum(c_flat[:, class_idx] == 1)) * 100\n",
        "\n",
        "        # Update total correct and total comparisons for overall accuracy\n",
        "        total_correct += correct\n",
        "        total_comparisons += total\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    overall_accuracy = (total_correct.float() / total_comparisons) * 100\n",
        "\n",
        "    # Open the file in write mode\n",
        "    with open(file_path, \"w\") as file:\n",
        "        # Write class-wise accuracies, false positives, and false negatives to the file\n",
        "        for class_idx, accuracy in enumerate(class_accuracies):\n",
        "            false_positive = false_positives[class_idx]\n",
        "            false_negative = false_negatives[class_idx]\n",
        "            file.write(f'Class {class_idx}: Accuracy = {accuracy.item():.2f}%, False Positives = {false_positive.item():.2f}%, False Negatives = {false_negative.item():.2f}%\\n')\n",
        "\n",
        "        # Write overall accuracy to the file\n",
        "        file.write(f'Overall Accuracy: {overall_accuracy.item():.2f}%\\n')"
      ],
      "metadata": {
        "id": "x0x9GSLtxsQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr = [0.8, 1.5]\n",
        "lr_2 = [0.8, 5, 10]\n",
        "# 85 -> 16 -> 50\n",
        "epoch_cnt = 2000\n",
        "c_dim = [24, 40]\n",
        "y_dim = [35, 50]\n",
        "num_concepts = 7\n",
        "\n",
        "for l in lr:\n",
        "  for l_2 in lr_2:\n",
        "    for cd in c_dim:\n",
        "      for yd in y_dim:\n",
        "        xclosses, cylosses, pred_c_list, pred_y_list, epochs, c, y = train(85,num_concepts,50,cd,yd,l, l_2, epoch_cnt)\n",
        "        plt.figure(figsize=(8, 6))  # create a new figure for each plot\n",
        "        plt.title('Cross Entropy Loss', pad = 20)\n",
        "        plt.xlabel('Epochs', labelpad = 20)\n",
        "        plt.ylabel('Loss AU')\n",
        "        plt.plot(epochs, xclosses, label = \"x_to_c\", linewidth=2)\n",
        "        plt.tight_layout()\n",
        "        plt.legend()\n",
        "        plt.savefig(f\"flat_seq_x_to_c_{cd}_{yd}_{epoch_cnt}_{l}_{l_2}_{num_concepts}.png\", bbox_inches='tight') # save the plot to disk\n",
        "        plt.close() # close the figure to free up memory\n",
        "\n",
        "        plt.figure(figsize=(8, 6))  # create a new figure for each plot\n",
        "        plt.title('Cross Entropy Loss', pad = 20)\n",
        "        plt.xlabel('Epochs', labelpad = 20)\n",
        "        plt.ylabel('Loss AU')\n",
        "        plt.plot(epochs, cylosses, label = \"c_to_y\", linewidth=2)\n",
        "        plt.tight_layout()\n",
        "        plt.legend()\n",
        "        plt.savefig(f\"flat_seq_c_to_y_{cd}_{yd}_{epoch_cnt}_{l}_{l_2}_{num_concepts}.png\", bbox_inches='tight') # save the plot to disk\n",
        "        plt.close() # close the figure to free up memory\n",
        "\n",
        "        calculate_and_save_accuracy(num_concepts, epoch_cnt, l, l_2, pred_c_list, c, f\"c_{cd}_{yd}\")\n",
        "\n",
        "        # Number of classes\n",
        "        y_classes = 50\n",
        "\n",
        "        # Create tensors to store class accuracies, false positives, and false negatives\n",
        "        y_accuracies = torch.zeros(y_classes)\n",
        "        y_false_positives = torch.zeros(y_classes)\n",
        "        y_false_negatives = torch.zeros(y_classes)\n",
        "\n",
        "        # Create variables to store total correct and total comparisons for overall accuracy\n",
        "        y_total_correct = 0\n",
        "        y_total_comparisons = 0\n",
        "\n",
        "        # Define file path for saving results\n",
        "        file_path2 = f\"label_accuracy_flat_seq_{cd}_{yd}_{epoch_cnt}_{l}_{l_2}_{num_concepts}.txt\"\n",
        "\n",
        "        # Correct shapes\n",
        "        pred_y_tensor = torch.tensor(pred_y_list)\n",
        "        pred_y = pred_y_tensor.view(-1, pred_y_tensor.size(-1))\n",
        "        y_flat = torch.cat(y, dim=0)\n",
        "\n",
        "        # Restrict the data to the last 500 samples\n",
        "        pred_y = pred_y[-500:]\n",
        "        y_flat = y_flat[-500:]\n",
        "\n",
        "        # Get the predicted class indices\n",
        "        predicted_classes = torch.argmax(pred_y, dim=1)\n",
        "\n",
        "        # Calculate class accuracies, false positives, and false negatives\n",
        "        for class_idx in range(y_classes):\n",
        "            correct = torch.sum((predicted_classes == class_idx) & (y_flat[:, class_idx] == 1))\n",
        "            total = torch.sum(y_flat[:, class_idx] == 1)\n",
        "            false_positive = torch.sum((predicted_classes == class_idx) & (y_flat[:, class_idx] == 0))\n",
        "            false_negative = torch.sum((predicted_classes != class_idx) & (y_flat[:, class_idx] == 1))\n",
        "\n",
        "            # Calculate class accuracy as a percentage\n",
        "            class_accuracy = (correct.float() / total) * 100\n",
        "            y_accuracies[class_idx] = class_accuracy\n",
        "\n",
        "            # Calculate false positives and false negatives as percentages\n",
        "            y_false_positives[class_idx] = (false_positive.float() /  torch.sum(y_flat[:, class_idx] == 0)) * 100\n",
        "            y_false_negatives[class_idx] = (false_negative.float() / total) * 100\n",
        "\n",
        "            # Update total correct and total comparisons for overall accuracy\n",
        "            y_total_correct += correct\n",
        "            y_total_comparisons += total\n",
        "\n",
        "        # Calculate overall accuracy\n",
        "        overall_accuracy = (y_total_correct.float() / y_total_comparisons) * 100\n",
        "\n",
        "        # Open the file in write mode\n",
        "        with open(file_path2, \"w\") as file:\n",
        "            # Write class-wise accuracies, false positives, and false negatives to the file\n",
        "            for class_idx, accuracy in enumerate(y_accuracies):\n",
        "                false_positive = y_false_positives[class_idx]\n",
        "                false_negative = y_false_negatives[class_idx]\n",
        "                file.write(f'Class {class_idx}: Accuracy = {accuracy.item():.2f}%, False Positives = {false_positive.item():.2f}%, False Negatives = {false_negative.item():.2f}%\\n')\n",
        "\n",
        "            # Write overall accuracy to the file\n",
        "            file.write(f'Overall Accuracy: {overall_accuracy.item():.2f}%\\n')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7bCHUdppXMRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683146b0-4000-4c1e-c3cf-8f8bb3d5a0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-2528a1cd042c>:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  pred_c_tensor = torch.tensor(pred_c_list)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "# Retrieve a list of file paths that match a pattern\n",
        "file_pattern = '*.png'  # Replace with your desired pattern\n",
        "file_paths = glob.glob(file_pattern)\n",
        "\n",
        "# Create a zip file\n",
        "zip_filename = 'plots.zip'\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    # Add all the files to the zip\n",
        "    for file_path in file_paths:\n",
        "        zipf.write(file_path)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Q1U4cQGjmJWM",
        "outputId": "4bb18d4b-9ef3-4235-a722-f8952bf93cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e3ea9344-1cfd-4e32-84aa-567d7a7e552f\", \"plots.zip\", 1614992)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve a list of file paths that match a pattern\n",
        "file_pattern = '*.txt'  # Replace with your desired pattern\n",
        "file_paths = glob.glob(file_pattern)\n",
        "\n",
        "# Create a zip file\n",
        "zip_filename = 'accuracies.zip'\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    # Add all the files to the zip\n",
        "    for file_path in file_paths:\n",
        "        zipf.write(file_path)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ERs0spUUmNjk",
        "outputId": "b39d8f4b-275f-4d12-afea-ffebac64d3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e5b19811-b597-4bc1-a68a-519f13252710\", \"accuracies.zip\", 127562)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}